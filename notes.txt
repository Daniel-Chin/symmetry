2022/4/13 {
    一阶 markov 有问题吗？
        z 里放 v
        RNN(z, h) 替换成 NN(z)
    东西全放到 h 里了怎么办？
        z 上加变换只是在和 encoder decoder 玩， 与 RNN 无关怎么办
        不可能。 RNN 的输入是 z. 
    双体
        只有二维椭圆轨道哦， ok? 
            ok
        渲染？ 更像 Junyan 还是更像 Xuanjie?
            xuanjie
        背景为黑
            doesn't matter
    读 S3 doc
        最小作用量 = 变分模拟
            和 GAN 有啥关系？
            这里， 物理规律的时候， EBM 的输入是时序。 
            GAN 没有时序， 但也是一种 EBM. 
        如果把对称性理解成 "minimize z capacity", 
            可以把 VAE 换成 AE, 然后加对称性。
        "用对称性去构建context dependency"
            我们做的对称性 focus on 时序规律
}
4/17 {
    evaluate disentanglement
        run linear regression z -> ball_pos
        look at r-squared
}
4/20 {
    two body:
        两个球半径一样？
            不一样？ encoder 无法区分半径和远近。
            let's make them the same. 
        z
            x1, y1, z1, x2, y2, z2
            the color needs to be different, otherwise encoder doesn't know which is which
        实验结果
            模拟
            预测
            解耦
    JEPA slides
}
4/22 {
    pretrain 单球， finetune 双体， 能否解耦双球坐标？
}
4/27 {
    糟糕，双体 DoF 只有 3, 因为质心固定。
        vary 质心？
        6 -> 3? 
        Gus: 6 -> 3
    极坐标不符合对称性规约?
        仅当起抛点固定时， 符合
    RNN 的弱性
        需要
    两点目标：
        datapoints 的 z 受对称性规约
        generalization (interpolation)
            如果不行， 那就是得每个位置的球都见过？
        try cycle
}
4/29 {
    loss 不应该除以 T 和 R
    RNN 预测应该跳过前三帧
}
5/4{
    cycle consistency:
        decoder 不变， encoder 变差
    slides/2d_rnn
        其中：
        有了 recon 也不一定就 不 collapse. 
            估计是为什么 xuanjie 在图片上作 loss 而不是 z 上。
    continue pyxuanjie on hpc, disentangle
        怎么和周五说的不一样
    ask yann / alf / cho
        for RNN, GRU, 
            besides hidden_dim, any other way to control its capacity? 
        what do you think of VRNN
}
next {
    VAE 需要数据多点
        我不确定这样做会不会有用
        测试 data efficiency 时， 能不能： 总图片数不变， sequence 数减少？
        用不成视频的图片训练 vae. 
    y is completely noy regularized! 
        many times, x and z are good, but y is piece-wise, and correlated with x, y. 
        VAE+RNN without symmetry can also provide piece-wise, almost-linear z space. 
    how to limit RNN/GRU?
        https://campuswire.com/c/GCEF8E4E7/feed/312
    pitch:
        one-hot vs one-dim
        both can translate!
    AE + symm 几乎总是会崩。 
        decoder gives rubbish when traversing z space. 
        但是 reconstruction 和预测都是好的。
        说明 overfit 非常严重， z space 只有寥寥几个点是正常的小球图片。
    为何 altitude ~ 0 的时候图片是糊的？ 未解之谜。
        it is very consistent. 
    看实验
        epoch_206000
}
6/1 {
    vvrnn
    vvrnn_static
    rnn_min_context
    z_pred_loss_coef
    试一试 平移 和 旋转 分开加
        T R TR I
    grad clip
        xuanjie: 
            1. early-stop before grad explosion
            2. diminishing lr
}
6/15 {
    note to self: if accidentally getting a fast GPU make you waste res, specify early stopping in code. 
}
6/16 {
    plot 1000-epoch loss average
}
6/18 {
    2080Ti: good to go. 
    According to loss plots, overfit happens around 2h of training. 
    神奇！ TR 就会预测不行， T+R 就会更好。
}
6/23 {
    stochastic TRI
        previously: every batch does a number of T+R+TR+I. Diff experiment groups will have diff # of trajectories because of this. 
        Now: stochastically sample one tranformation from the TRI spectification. # of trajs is thus controlled across groups. 
    TRI_5
        the loss still jumps up from time to time! Why? already grad clip. 
}
next {
    try BCE instead of MSE
        maybe replace tanh with sigmoid
}

archive {
    有些结， 升一维就能解开。 暂时升一维， 等会儿降回来？
}
